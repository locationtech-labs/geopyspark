""""This module contains functions that create RasterRDDs from files.

There is only one function found within this module at this time, geotiff_rdd.
"""

from geopyspark.geotrellis.rdd import RasterRDD

def get(geopysc,
        rdd_type,
        uri,
        options=None,
        **kwargs):

    """Creates a RasterRDD from GeoTiffs that are located on the local file system, HDFS, or S3.

    Args:
        geopysc (GeoPyContext): The GeoPyContext being used this session.
        rdd_type (str): What the spatial type of the geotiffs are. This is
            represented by the constants: `SPATIAL` and `SPACETIME`.

            Note:
                All of the GeoTiffs must have the same saptial type.
        uri (str): The path to a given file/directory.
        options (dict, optional): A dictionary of different options that are used
            when creating the RDD. This defaults to None. If None, then the
            RDD will be created using the default options for the given backend
            in GeoTrellis. Note: key values should be in camel case, as this is
            the style that is used in Scala.

            These are the options when using the local file system or HDFS:
                * **crs** (str, optional): The CRS that the output tiles should be
                    in. The CRS must be in the well-known name format. If None,
                    then the CRS that the tiles were originally in will be used.
                * **timeTag** (str, optional): The name of the tiff tag that contains
                    the time stamp for the tile. If None, then the default value
                    is: 'TIFFTAG_DATETIME'.
                * **timeFormat** (str, optional): The pattern of the time stamp for
                    java.time.format.DateTimeFormatter to parse. If None,
                    then the default value is: 'yyyy:MM:dd HH:mm:ss".
                * **maxTileSize** (int, optional): The max size of each tile in the
                    resulting RDD. If the size is smaller than a read in tile,
                    then that tile will be broken into tiles of the specified
                    size. If None, then the whole tile will be read in.
                * **numPartitions** (int, optional): The number of repartitions Spark
                    will make when the data is repartitioned. If None, then the
                    data will not be repartitioned.
                * **chunkSize** (int, optional): How many bytes of the file should be
                    read in at a time. If None, then files will be read in 65536
                    byte chunks.

            S3 has the above options in addition to this:
                * **s3Client** (st, optional): Which S3Cleint to use when reading
                    GeoTiffs. There are currently two options: 'default' and
                    'mock'. If None, 'defualt' is used. Note: 'mock' should
                    only be used in unit tests.

        **kwargs: Option parameters can also be entered as keyword arguements.

    Note:
        Defining both `options` and `kwargs will cause the `kwargs` to be ignored in favor
        of `options`.

    Returns:
        :class:`~geopyspark.geotrellis.rdd.RasterRDD`
    """

    geotiff_rdd = geopysc._jvm.geopyspark.geotrellis.io.geotiff.GeoTiffRDD

    key = geopysc.map_key_input(rdd_type, False)

    if kwargs and not options:
        options = kwargs

    if options:
        srdd = geotiff_rdd.get(geopysc.sc,
                               key,
                               uri,
                               options)
    else:
        srdd = geotiff_rdd.get(geopysc.sc,
                               key,
                               uri)

    return RasterRDD(geopysc, rdd_type, srdd)
